\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Bayesian statistics and Markov chain Monte Carlo}{1}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Bayes' formula}{1}{subsection.1.1}}
\newlabel{eq:BayesRule}{{1}{1}{Bayes' formula}{equation.1.1}{}}
\MT@newlabel{eq:BayesRule}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Parametrized models}{1}{subsection.1.2}}
\newlabel{eq:GaussianNoise}{{2}{2}{Parametrized models}{equation.1.2}{}}
\MT@newlabel{eq:GaussianNoise}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.2.1}An example: parametrized differential equations}{2}{subsubsection.1.2.1}}
\newlabel{sect:exBayes}{{1.2.1}{2}{An example: parametrized differential equations}{subsubsection.1.2.1}{}}
\newlabel{eq:exSDE}{{3}{2}{An example: parametrized differential equations}{equation.1.3}{}}
\MT@newlabel{eq:exSDE}
\MT@newlabel{eq:exSDE}
\citation{Gil05}
\citation{KaS05}
\citation{KaS05}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}Markov chain Monte Carlo methods}{3}{subsection.1.3}}
\newlabel{eq:MonteCarloMCMC}{{4}{3}{Markov chain Monte Carlo methods}{equation.1.4}{}}
\citation{MLR16}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces Metropolis-Hastings.\relax }}{4}{algocf.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{alg:MH}{{1}{4}{Metropolis-Hastings algorithm}{algocf.1}{}}
\MT@newlabel{eq:MHalpha}
\MT@newlabel{eq:MonteCarloMCMC}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.1}Metropolis-Hastings algorithm}{4}{subsubsection.1.3.1}}
\newlabel{eq:MHalpha}{{5}{4}{Metropolis-Hastings algorithm}{equation.1.5}{}}
\citation{Vih12}
\citation{Vih12}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Robust adaptive Metropolis.\relax }}{5}{algocf.2}}
\newlabel{alg:RAM}{{2}{5}{An adaptive approach}{algocf.2}{}}
\MT@newlabel{eq:MHalpha}
\MT@newlabel{eq:RAMupdate}
\newlabel{eq:MHalphasym}{{6}{5}{Metropolis-Hastings algorithm}{equation.1.6}{}}
\newlabel{eq:gaussianProp}{{7}{5}{Metropolis-Hastings algorithm}{equation.1.7}{}}
\MT@newlabel{eq:MHalphasym}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.2}An adaptive approach}{5}{subsubsection.1.3.2}}
\MT@newlabel{eq:gaussianProp}
\citation{DPD15}
\citation{ADH10}
\newlabel{eq:RAMupdate}{{8}{6}{An adaptive approach}{equation.1.8}{}}
\newlabel{eq:RAMtestPi}{{9}{6}{An adaptive approach}{equation.1.9}{}}
\MT@newlabel{eq:RAMtestPi}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Acceptance ratios for MH and RAM with posterior distribution \MT_extended_eqref:n  {eq:RAMtestPi}\relax }}{6}{table.caption.3}}
\MT@newlabel{eq:RAMtestPi}
\newlabel{tab:RAMalphaStar}{{1}{6}{Acceptance ratios for MH and RAM with posterior distribution \eqref {eq:RAMtestPi}\relax }{table.caption.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.3}Pseudo-marginal Metropolis-Hastings}{6}{subsubsection.1.3.3}}
\newlabel{sec:MCWM}{{1.3.3}{6}{Pseudo-marginal Metropolis-Hastings}{subsubsection.1.3.3}{}}
\citation{AnR09}
\citation{MLR16}
\citation{AnR09}
\citation{MLR16}
\citation{AnR09}
\citation{MLR16}
\citation{MLR16}
\citation{KPS94}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Samples produced by MH and RAM for the distribution \MT_extended_eqref:n  {eq:RAMtestPi}. The contour lines of the density function are plotted for all the sets of results. In the first row we show the results obtained with MH for a normal update with covariance $\Sigma = \sigma ^2 I $ with $\sigma = \{0.01, 0.5, 2.0\}$ from left to right. In the second row we show the results obtained with RAM with the same values of $\Sigma $ as an initial guess of the covariance structure. \relax }}{7}{figure.caption.4}}
\MT@newlabel{eq:RAMtestPi}
\newlabel{fig:RAMexample}{{1}{7}{Samples produced by MH and RAM for the distribution \eqref {eq:RAMtestPi}. The contour lines of the density function are plotted for all the sets of results. In the first row we show the results obtained with MH for a normal update with covariance $\Sigma = \sigma ^2 I $ with $\sigma = \{0.01, 0.5, 2.0\}$ from left to right. In the second row we show the results obtained with RAM with the same values of $\Sigma $ as an initial guess of the covariance structure. \relax }{figure.caption.4}{}}
\newlabel{eq:MCWMestimators}{{10}{7}{Pseudo-marginal Metropolis-Hastings}{equation.1.10}{}}
\newlabel{eq:MCWMalpha}{{11}{7}{Pseudo-marginal Metropolis-Hastings}{equation.1.11}{}}
\MT@newlabel{eq:MCWMalpha}
\@writefile{loa}{\contentsline {algocf}{\numberline {3}{\ignorespaces Monte Carlo within Metropolis.\relax }}{8}{algocf.3}}
\newlabel{alg:MCWM}{{3}{8}{Pseudo-marginal Metropolis-Hastings}{algocf.3}{}}
\MT@newlabel{eq:MCWMestimators}
\MT@newlabel{eq:MCWMalpha}
\MT@newlabel{eq:MCWMestimators}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.4}How to deal with inadmissible parameter values}{8}{subsubsection.1.3.4}}
\newlabel{eq:truncGauss}{{12}{8}{How to deal with inadmissible parameter values}{equation.1.12}{}}
\MT@newlabel{eq:truncGauss}
\citation{GeS11}
\citation{GeS11}
\@writefile{loa}{\contentsline {algocf}{\numberline {4}{\ignorespaces Monitoring convergence.\relax }}{9}{algocf.4}}
\newlabel{alg:Convergence}{{4}{9}{Monitoring convergence}{algocf.4}{}}
\MT@newlabel{eq:RhoMCMC}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.5}Monitoring convergence}{9}{subsubsection.1.3.5}}
\newlabel{eq:RhoMCMC}{{13}{9}{Monitoring convergence}{equation.1.13}{}}
\citation{CGS16}
\@writefile{toc}{\contentsline {section}{\numberline {2}Probabilistic Methods}{10}{section.2}}
\newlabel{ODE}{{14}{10}{Probabilistic Methods}{equation.2.14}{}}
\MT@newlabel{ODE}
\newlabel{numericalODE}{{2}{10}{Probabilistic Methods}{equation.2.14}{}}
\MT@newlabel{ODE}
\newlabel{probabilityODE}{{15}{10}{Probabilistic Methods}{equation.2.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Deterministic methods}{10}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Motivation}{10}{subsection.2.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.2.1}Numerical example}{10}{subsubsection.2.2.1}}
\newlabel{eq:Lorenz}{{16}{10}{Numerical example}{equation.2.16}{}}
\MT@newlabel{eq:Lorenz}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Method properties}{11}{subsection.2.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Strong convergence}{11}{subsubsection.2.3.1}}
\MT@newlabel{probabilityODE}
\newlabel{thm:Gronwall}{{2.1}{11}{Discrete Gronwall Lemma}{theorem.2.1}{}}
\newlabel{assumption_1}{{2.1}{11}{}{assumption.2.1}{}}
\MT@newlabel{probabilityODE}
\newlabel{assumption_2}{{2.2}{11}{}{assumption.2.2}{}}
\newlabel{thm:strongConv}{{2.2}{11}{Strong Convergence}{theorem.2.2}{}}
\newlabel{strongConvDisc}{{2.2}{11}{Strong Convergence}{theorem.2.2}{}}
\newlabel{strongConvCont}{{2.2}{11}{Strong Convergence}{theorem.2.2}{}}
\MT@newlabel{probabilityODE}
\MT@newlabel{ODE}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Weak convergence}{12}{subsubsection.2.3.2}}
\MT@newlabel{ODE}
\MT@newlabel{probabilityODE}
\newlabel{LieNotation}{{17}{12}{Weak convergence}{equation.2.17}{}}
\newlabel{modifiedODE}{{2.3.2}{12}{Weak convergence}{equation.2.17}{}}
\citation{CGS16}
\citation{CGS16}
\newlabel{modifiedSDE}{{18}{13}{Weak convergence}{equation.2.18}{}}
\MT@newlabel{LieNotation}
\newlabel{LieNotationModif}{{2.3.2}{13}{Weak convergence}{equation.2.18}{}}
\MT@newlabel{modifiedSDE}
\newlabel{assumption_3}{{2.3}{13}{}{assumption.2.3}{}}
\MT@newlabel{ODE}
\newlabel{thm:weakorder}{{2.3}{13}{}{theorem.2.3}{}}
\MT@newlabel{probabilityODE}
\MT@newlabel{ODE}
\MT@newlabel{modifiedSDE}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.3}Numerical verification of weak order}{13}{subsubsection.2.3.3}}
\MT@newlabel{ODE}
\newlabel{eq:FitzNag}{{19}{13}{Numerical verification of weak order}{equation.2.19}{}}
\MT@newlabel{probabilityODE}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Weak order of convergence of \MT_extended_eqref:n  {probabilityODE} applied to \MT_extended_eqref:n  {eq:FitzNag}.\relax }}{14}{figure.caption.7}}
\MT@newlabel{probabilityODE}
\MT@newlabel{eq:FitzNag}
\newlabel{fig:weakorder}{{2}{14}{Weak order of convergence of \eqref {probabilityODE} applied to \eqref {eq:FitzNag}.\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.4}Monte Carlo approximation}{14}{subsubsection.2.3.4}}
\MT@newlabel{probabilityODE}
\newlabel{eq:MCapproximation}{{20}{14}{Monte Carlo approximation}{equation.2.20}{}}
\newlabel{eq:MCMSE}{{2.3.4}{14}{Monte Carlo approximation}{equation.2.20}{}}
\newlabel{lem:varMC}{{2.1}{14}{}{lemma.2.1}{}}
\MT@newlabel{probabilityODE}
\newlabel{eq:indepProof}{{21}{14}{Monte Carlo approximation}{equation.2.21}{}}
\newlabel{eq:varProp}{{22}{15}{Monte Carlo approximation}{equation.2.22}{}}
\newlabel{eq:lipschitzVar}{{23}{15}{Monte Carlo approximation}{equation.2.23}{}}
\newlabel{eq:boundOfSum}{{24}{15}{Monte Carlo approximation}{equation.2.24}{}}
\MT@newlabel{probabilityODE}
\MT@newlabel{eq:varProp}
\newlabel{eq:temp}{{25}{16}{Monte Carlo approximation}{equation.2.25}{}}
\MT@newlabel{eq:temp}
\newlabel{lem:varimRK}{{2.2}{16}{}{lemma.2.2}{}}
\MT@newlabel{probabilityODE}
\MT@newlabel{eq:indepProof}
\MT@newlabel{eq:lipschitzVar}
\MT@newlabel{eq:varProp}
\MT@newlabel{eq:lipschitzVar}
\newlabel{eq:partialLemRKI}{{26}{17}{Monte Carlo approximation}{equation.2.26}{}}
\MT@newlabel{eq:varProp}
\MT@newlabel{eq:lipschitzVar}
\MT@newlabel{eq:varProp}
\MT@newlabel{eq:partialLemRKI}
\citation{CGS16}
\MT@newlabel{eq:boundOfSum}
\MT@newlabel{eq:MCapproximation}
\newlabel{prop:MSE}{{2.4}{18}{}{theorem.2.4}{}}
\MT@newlabel{eq:lipschitzVar}
\newlabel{fig:MonteCarloVarianceH}{{3a}{19}{Variation of the time step.\relax }{figure.caption.8}{}}
\newlabel{sub@fig:MonteCarloVarianceH}{{a}{19}{Variation of the time step.\relax }{figure.caption.8}{}}
\newlabel{fig:MonteCarloVarianceM}{{3b}{19}{Variation of the number of trajectories.\relax }{figure.caption.8}{}}
\newlabel{sub@fig:MonteCarloVarianceM}{{b}{19}{Variation of the number of trajectories.\relax }{figure.caption.8}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Variance and squared bias of the Monte Carlo estimator $\mathaccentV {hat}05EZ$ with Explicit Euler and RK4 applied to \MT_extended_eqref:n  {eq:FitzNag}. The two components of the MSE have the same order of convergence with respect to the time step $h$. Conversely, the order of convergence with respect to the number of trajectories $M$ with fixed $h$ of the variance of $\mathaccentV {hat}05EZ$ is equal to one for both methods\relax }}{19}{figure.caption.8}}
\MT@newlabel{eq:FitzNag}
\newlabel{fig:MonteCarloVariance}{{3}{19}{Variance and squared bias of the Monte Carlo estimator $\hat Z$ with Explicit Euler and RK4 applied to \eqref {eq:FitzNag}. The two components of the MSE have the same order of convergence with respect to the time step $h$. Conversely, the order of convergence with respect to the number of trajectories $M$ with fixed $h$ of the variance of $\hat Z$ is equal to one for both methods\relax }{figure.caption.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.5}Numerical experiment}{19}{subsubsection.2.3.5}}
\MT@newlabel{eq:FitzNag}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Stability analysis}{20}{subsection.2.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}To do at Christmas}{20}{subsection.2.5}}
\citation{ADH10}
\citation{DPD15}
\citation{PSG12}
\@writefile{toc}{\contentsline {section}{\numberline {3}Bayesian inference of the parameters of an ODE}{21}{section.3}}
\newlabel{eq:ODEParam}{{27}{21}{Bayesian inference of the parameters of an ODE}{equation.3.27}{}}
\MT@newlabel{eq:ODEParam}
\MT@newlabel{eq:ODEParam}
\newlabel{eq:BayesODE}{{28}{21}{Bayesian inference of the parameters of an ODE}{equation.3.28}{}}
\newlabel{eq:likelihood}{{3}{21}{Bayesian inference of the parameters of an ODE}{equation.3.28}{}}
\MT@newlabel{eq:ODEParam}
\MT@newlabel{eq:BayesODE}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Approximation of the likelihood}{21}{subsection.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Approximation of the likelihood at a fixed value $\mathaccentV {bar}016\theta $.\relax }}{22}{figure.caption.9}}
\newlabel{fig:MonteCarloVarianceH}{{4}{22}{Approximation of the likelihood at a fixed value $\bar \theta $.\relax }{figure.caption.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.1.1}Numerical example}{22}{subsubsection.3.1.1}}
\MT@newlabel{eq:FitzNag}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Numerical example}{22}{subsection.3.2}}
\MT@newlabel{eq:FitzNag}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Posterior distribution for the parameter $\theta $ defining the FitzHug-Nagumo model. The posterior distributions given by the probabilistic and the deterministic solvers are displayed in blue and red respectively. The true value of the parameters is displayed in thick green dots.\relax }}{23}{figure.caption.10}}
\newlabel{fig:MCMC_FHN}{{5}{23}{Posterior distribution for the parameter $\theta $ defining the FitzHug-Nagumo model. The posterior distributions given by the probabilistic and the deterministic solvers are displayed in blue and red respectively. The true value of the parameters is displayed in thick green dots.\relax }{figure.caption.10}{}}
\citation{GiS02}
\citation{GiS02}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Convergence of the posterior distribution}{24}{subsection.3.3}}
\newlabel{eq:TVvsHell}{{29}{24}{Convergence of the posterior distribution}{equation.3.29}{}}
\MT@newlabel{eq:TVvsHell}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Convergence of the Monte Carlo estimation}{25}{subsection.3.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.4.1}Numerical experiment}{25}{subsubsection.3.4.1}}
\MT@newlabel{eq:FitzNag}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Convergence of the parameter to its stationary value and of the Hellinger distance of the probability distributions.\relax }}{26}{figure.caption.11}}
\newlabel{fig:ConvergenceMCMC}{{6}{26}{Convergence of the parameter to its stationary value and of the Hellinger distance of the probability distributions.\relax }{figure.caption.11}{}}
\bibstyle{siam}
\bibdata{anmc.bib}
\bibcite{ADH10}{1}
\bibcite{AnR09}{2}
\bibcite{CGS16}{3}
\bibcite{DPD15}{4}
\bibcite{GeS11}{5}
\bibcite{GiS02}{6}
\bibcite{Gil05}{7}
\bibcite{KaS05}{8}
\bibcite{KPS94}{9}
\bibcite{MLR16}{10}
\bibcite{PSG12}{11}
\bibcite{Vih12}{12}
