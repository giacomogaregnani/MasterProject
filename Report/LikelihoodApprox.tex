\subsection{Approximation of the likelihood}

An unbiased estimator of the likelihood has to be obtained at each step of the MCMC algorithm in order to compute the acceptance probability. In particular, we approximate the likelihood using the probabilistic solver with time step $h$, thus obtaining the approximation a Monte Carlo estimation obtained with $M$ simulated trajectories with time step $h$, i.e., for each value of $\theta$ we consider
\begin{equation}
	\diffL(\mathcal Y|\theta) \approx \diffL^h(\mathcal Y|\theta).
\end{equation}
Then, we approximate the value of $\diffL^h$ with a Monte Carlo simulation thus obtaining the following unbiased estimator
\begin{equation}
	\diffL_M^h(\mathcal Y | \theta)  \approx \diffL^h(\mathcal Y|\theta).
\end{equation}
We then use this value for computing the acceptance probability in a MWCM algorithm (see Section \ref{sec:MCWM}) to perform Bayesian inference on the value of the parameter $\theta$. A question which often arises in literature \cite{ADH10, DPD15, PSG12} is how many samples $M$ it would be advisable to choose in order to consider the obtained posterior distribution a good approximation of the true posterior. For each value of $\theta$, we can apply Proposition \ref{prop:MSE}, thus obtaining 
\begin{equation}
	\MSE(\diffL_M^h(\mathcal Y | \theta)) \leq C_1 h^{2\min\{2p, q\}} + \frac{C_2}{M} h^{2p}.
\end{equation}
Therefore, at each step of the MCMC algorithm we can control with the time step the goodness of the likelihood estimator.

\input{NumericalLikelihood}