\subsubsection{An adaptive approach}

In the frame of MH algorithms, it is important to have a control on the \textit{acceptance ratio} of the Markov chain, i.e., the number of new guesses that are chosen over the previous value of $\theta$. The acceptance ratio depends on the goodness of the chosen proposal distribution, as if the new guess produced via the proposal distribution have a low probability of being accepted, a low value of acceptance ratio will result from the algorithm. In order to overcome this issue, we choose to adopt the robust adaptive Metropolis-Hastings algorithm (RAM) \cite{Vih12}. Let us consider the case in which the proposal distribution is normal, i.e.,
\begin{equation}
	\vartheta = \theta_k + Z, \quad Z \sim \mathcal{N}(0, \Sigma),
\end{equation}
with a given covariance matrix $\Sigma$. It is possible to build a sequence of matrices such that the convergence properties of MH are not spoiled and the acceptance rate is approximately equal to a given value $\alpha^*$. In particular, we consider for each iteration $n = 1, \ldots, N$, the update 
\begin{equation}
	\vartheta = \theta_k + S_n Z_n, \quad Z_n \sim \mathcal{N}(0, I),
\end{equation}
with $S_n$ a lower triangular positive definite matrix and $I$ the identity matrix. Then, once the probability $\alpha$ of acceptance has been computed, we update $S_n$ with a lower triangular matrix $S_{n+1}$ satisfying
\begin{equation}
	S_{n+1}S_{n+1}^T = S_n\left(I + \eta_n\left(\alpha - \alpha^*\right)\frac{Z_nZ_n^T}{Z_n^TZ_n}\right)S_n^T.
\end{equation}
Hence, we can compute $S_{n+1}$ as the Cholesky factorization of the right hand side. The sequence $\left\{\eta_n\right\}_n$ can be any sequence decaying to zero with $n$. In this work, we consider
\begin{equation}
	\eta_n = n^{-\gamma}, \quad 0.5 < \gamma \leq 1.
\end{equation}
This algorithm guarantees that the final acceptance rate of MH will be asymptotically equal to the desired value $\alpha^*$ \cite{Vih12}.