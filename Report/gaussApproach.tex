\subsubsection{A Gaussian filtering approach}

An interesting approach for the Bayesian analysis of the parameters of an ODE or of an SDE has been recently proposed in \cite{SHM15}. In this paper, the authors propose a Gaussian filtering approach to solve the differential equation at each step of an MCMC algorithm, avoiding in this way the computationally inefficient Monte Carlo simulation typical of the MCWM approach. The method consists in building at each iteration of the MCMC algorithm a Gaussian approximation of the solution of an SDE, computing the evolution of the mean and variance of a Gaussian distribution with an ODE approach. Let us consider the acceptance probability in a standard MH
\begin{equation}
	\alpha = \min\left\{\frac{\mathcal Q(\vartheta) \diffL(d|\vartheta)}{\mathcal Q(\theta_k) \diffL(d|\theta_k)}\right\}.
\end{equation}
While the prior distribution is easy to evaluate, the likelihood function is in this case intractable. The pseudo-marginal MCMC approach and its noisy version approximate the likelihood with a Monte Carlo simulation, which can be extremely costly. \\
Let us consider $f\colon\R^{N_s}\to\R^{N_s}$, $g\colon\R^{N_s}\to\R^{N_s\times N_s}$, $W$ a $d$-dimensional Wiener process and the following SDE
\begin{equation}\label{eq:SDE}
\begin{aligned}
	\dd U(t; \theta) &= f_{\theta}(U) \dd t + g_{\theta}(U) \dd W, && 0 < t \leq T,\\
	U(0) &= U_0,
\end{aligned}
\end{equation}
where we assume that $U_0$ is a deterministic initial condition in $\R^{N_s}$ and that the functions $f,g$ depend on a parameter $\theta$ of $\R^{N_p}$. Under Assumption \ref{assumption_1} with $Q = \sigma I$ , solving an ODE with the probabilistic method defined in \eqref{probabilityODE} is equivalent to solving numerically \eqref{eq:SDE} for the choice
\begin{equation}
	g(U) = G = \sigma h^p I,
\end{equation}
with $I$ the identity matrix in $\R^{N_s\times N_s}$. Since the method proposed in \cite{SHM15} is applicable to any SDE of the form \eqref{eq:SDE}, in the following we formally maintain this more general notation. Let us denote by $y_i$ an observation of the state of \eqref{eq:SDE} at time $t_i$ for $i = 1, \ldots, N_d$, and by $Y_i$ the set of all observations up to time $t_i$, i.e.,
\begin{equation}
	Y_i = \left\{y_1, y_2, \ldots, y_{i-1}, y_i \right\}.
\end{equation}
Let us furthermore assume that $y_i$ is measured from the solution with the following additive noise model
\begin{equation}
	y_i = U(t_i) + \epl_i, \quad \epl_i \sim \mathcal{N}(0, \Sigma_y).
\end{equation}
The likelihood appearing in the probability $\alpha$ can be therefore written as
\begin{equation}
\begin{aligned}
	\diffL(Y_k|\theta) &= \prod_{i=1}^{k} (2\pi\det(\Sigma_y))^{-k/2}\exp\left(-\frac{1}{2}(U(t_i;\theta) - y_i)^T\Sigma_y^{-1}(U(t_i;\theta) - y_i)\right) \\
					   &= \prod_{i=1}^{k} \diffL_i(y_i|\theta).
\end{aligned}
\end{equation}

