\documentclass[10pt]{article}

\input{ex_shared}

\begin{document}
	\maketitle	

We thank the reviewers for their numerous comments and we are confident that clarifying certain aspects will help us to consistently ameliorate our work. We divided our answer in three sections. In Section 1, we discuss the modifications of Section 7 (Hamiltonian systems), since both referees had multiple comments about this part of our work. In Section 2 and Section 3 we answer separately to the comments of Reviewer \#1 and \#2, respectively, about the other topics treated by our work.

Some comments are not directly addressed in this report (e.g., language/syntax issues, typos, slight notation changes) but have nonetheless been considered in the rewriting of our paper.

\section{Modifications of Section 7}

Both Reviewer \#1 and Reviewer \#2 have multiple comments regarding symplecticity and the long-time conservation of Hamiltonians. Since we believe that this section may be the most relevant of our work, and that it is for sure the one presenting the most tedious calculations, we decided to let it undergo a thorough revision process and to dedicate it a separate section in this response. In the following, we highlight the major modifications.

\begin{enumerate}
	\item \textbf{Answer to the following comment by Reviewer \#1}
	\begin{itquote}
		The authors should demonstrate that the decomposition that occurs over (84), (85), and (86) is correct by showing the intermediate decompositions. For example, the decomposition could be formulated as a lemma using arbitrary quantities, e.g. $a_j$ instead of $\eta_j$ and $b_{j,k}$ instead of $(H^k_j-h^k)\Delta_{j,k}$, so that the reader can see and verify the correctness of the decomposition, without having to do so in terms of the visually more complicated $(H^k_j-h^k)\Delta_{j,k}$. The estimates in (87) and (88) should also be given in separate lemmas, each with their own proofs.
	\end{itquote}
	The proof of Theorem 6 has been shortened to make it easier for the reader to follow our reasoning and the calculations. This is achieved by the introduction of two lemmas (Lemma 7 and Lemma 8), where the most technical steps are performed. In particular, Lemma 7 deals with the decomposition of the sum, and Lemma 8 with the bound of the remainder terms. Since the proofs of these two results involve tedious calculations, we moved them to the Appendix, so that an interested reader can still verify their rightfulness. We thank Reviewer \#1 for having pointed out this lack of clarity, as we believe that now our manuscript is dealing with these technical steps in a much clearer manner.
	\item \textbf{Answer to the following comments by Reviewer \#2}
	\begin{itquote}
		After Eq. (63): is $Q$ required to be a polynomial or $\nabla Q$?\\
		Try to given an outline of the argument where $\kappa$ comes from.\\
		Can you give a specific reference that explains the existence of $\tilde Q$ in (70)?
	\end{itquote}
	Concerning the first question, neither $Q$ nor $\nabla Q$ are required to be polynomials, but assumptions on the smoothness of $Q$ are needed for the analysis of long-time conservation to hold (Assumption 5). Methods for conserving \textit{exactly} polynomial first integrals can be designed, and we explain the properties of their RTS-RK counterpart in Section 6. In Section 7 our goal is to observe the \textit{good approximation} of Hamiltonian functions provided by symplectic integrators.\\
	Concerning the second and third questions, we believe that these points are clearly exposed in \cite[Chapter IX]{HLW06}. We added precise citations in the text in order to clarify this. 
	\item \textbf{Answer to the following comment by Reviewer \#1}
	\begin{itquote}
		$H_k$ is selected via a random mapping $\tau(y,h)=\tau(h)=h\Theta_k$, where $\Theta_k$ are opportunely scaled ...' -- Do the authors mean that $H_k=\tau(y,h)=h\Theta_k$? If so, they should explicitly state this. I did not find 'is selected via' to be sufficiently clear.
	\end{itquote}
	\textbf{and to the following comments by Reviewer \#2}
	\begin{itquote}
		Maybe hint at the argument why $\tau(y, h)$ exists and why $\Theta_k$ exists without violating Assumption 1 .\\
		The authors reference the paper by Skeel \& Gear. Given the main reference through the rest of the text is \cite{HLW06}, maybe the authors could use the notation thereof and point to specific sections of \cite{HLW06}.\\
		How can I see from (66) that (65) is satisfied?
	\end{itquote}
	The mapping $\tau(y, h)$ and $\Theta_k$ trivially exist by defining $\Theta_k \defeq H_k / h$, and $\tau(y, h) = h \Theta_k$. The fact we would like to highlight with Lemma 5 is that the numerical flow $\Psi_{\tau(y, h)}$ conserves the property of symplecticity when the choice of $h$ is independent of $y$. This is not the case when $h$ is chosen via standard adaptive techniques, which pick time steps as a function of error estimators, which are based on the solution. In our case, we have $\partial_y \tau(y, h) = 0$ and therefore (65) (with Definition 4) is trivially satisfied. Finally, we added a reference to \cite[Section VIII.1]{HLW06}, where these issues are treated thoroughly. We believe that with the modifications we made, the proof of Lemma 5 should be clear for a reader of Statistics and Computing.
	\item \textbf{Answer to the following comment by Reviewer \#2}
	\begin{itquote}
		Lemma 6: I found the arguments of the proof helpful for following the text. Consider putting it in the main body.
	\end{itquote}
	While we believe that building a geometry-aware probabilistic integrator may be the central result of our work, we would not want the reader to be distracted from the main messages by tedious computations. That is the reasoning behind our choice of placing the proof of Lemma 6 (and of the new Lemma 7 and Lemma 8) in the Appendix. Therefore, we decided to keep them in the Appendix in this revised version, and hope that this is satisfactory for both the referees. 
	\item \textbf{Answer to the following comment by Reviewer \#1}
	\begin{itquote}
		Do the authors intend for (74) to be the definition of the $\eta_j$'s? If so, then they should explicitly state this, reformulate (74), and use the '$\defeq$' notation if possible to indicate that a definition is being made, instead of an assertion of equality between two objects. -- The authors should state the statistical properties of the $\eta_j$'s, e.g. whether or not they are independent with respect to certain random variables, whether or not they are identically distributed, etc. They should provide justifications for these assertions. Doing so provides a useful service to readers who wish to verify that the proof of Theorem 6 is correct. -- It is not clear why the $\eta_j$'s satisfy $\vert\eta_j\vert\leq CH_j e^{-\kappa/H_j}$ almost surely. Provide an explanation.
	\end{itquote}
	\textbf{and to the following comment by Reviewer \#2}
	\begin{itquote}
		How can I see that (74) can be written thusly?
	\end{itquote}
	Equation (74) appears now reversed in order to make it a proper definition of the variables $\eta_j$. Regarding the almost sure bound $\abs{\eta_j} \leq CH_je^{-\kappa/H_j}$, we found a mistake in equation (71), which in its previous version stated
	\begin{equation*}
		\abs{Q(\Psi_h(y)) - Q(y)} \leq Che^{-\kappa/h}.
	\end{equation*}
	The inequality above is indeed not correct, but it holds for the modified Hamiltonian as
	\begin{equation*}
	\abs{\tilde Q(\Psi_h(y)) - \tilde Q(y)} \leq Che^{-\kappa/h}.
	\end{equation*}
	For a reference of the latter, see \cite[Theorem IX.7.6]{HLW06} and the proof of \cite[Theorem IX.8.1]{HLW06}. In particular, this implies by definition of the modified Hamiltonian that for any $y \in \R^{2d}$ we have
	\begin{equation*}
		\Big\lvert Q(y) - Q(\Psi_h(y)) + \sum_{k=q}^{N-1} h^k \big(Q_{k+1}(y) - Q_{k+1}(\Psi_h(y))\big)\Big\rvert \leq Che^{-\kappa/h}.
	\end{equation*}
	Replacing $h$ with $H_j$, one gets the almost sure bound $\abs{\eta_j} \leq CH_je^{-\kappa/H_j}$. Indeed, the difference between the modified Hamiltonian $\tilde Q$ and the local modified Hamiltonians $\hat Q_j$ is their global vs. local nature. Hence, on a local level the two quantities behave in the same manner. In order to clarify this point, we added in the text a reference to (71) when stating the bound on the (random) local truncation error $\eta_j$.
	
	Regarding the statistical properties of the $\eta_j$'s, not much can be stated. In fact, we have that $\eta_j$ and $\eta_i$ for $i\neq j$, are not independent random variables. In fact, when following a trajectory, the variable $\eta_j$ depends on $Y_j$ (respectively $\eta_i$ and $Y_i$), and since $Y_i$ and $Y_j$ are not independent, the variables $\eta_j$ and $\eta_i$ are not independent. Nonetheless, the almost sure bounds $\abs{\eta_j} \leq CH_je^{-\kappa/H_j}$ form a sequence of independent random variables, as the constant $C$ is independent of $y$ (see \cite[Theorem IX.7.6]{HLW06}) and the random time steps are independent under Assumption 1. This means that we can compute, for example,
	\begin{equation}
		\E \eta_i \eta_j \leq C \E H_j e^{-\kappa/H_j} H_i e^{-\kappa/H_i} = C \E H_j e^{-\kappa/H_j} \E H_i e^{-\kappa/H_i},
	\end{equation}
	and then use the result provided by Lemma 6 to proceed with calculations. We employ this property in the proof of Lemma 8. 
	\item \textbf{Answer to the following comments by Reviewer \#1}
	\begin{itquote}
		``Moreover, for any $r,s>1$ such that $r+s<R$'' $\to$ ``Then for any $r,s>1$ such that $r+s<R$.'' This hypothesis should be stated explicitly. In addition, since the authors have not explicitly proof that value of $C$ may change from line to line, inequality is strictly speaking false. problem can resolved by adding a factor 2 or stating at beginning proof.
	\end{itquote}
	We updated our text to clarify this point, with a particular care on the value of the constants, which, in fact, were not correct in the previous version. 
	\item \textbf{Answer to the following comments by Reviewer \#1}
	\begin{itquote}
		``\ldots if the numerical solution $y_n$ \ldots is close enough to the initial condition'' [\ldots] The constraint that the numerical solution ``is close enough to the initial condition'' is vague. Theorem IX.8.1. of reference \cite{HLW06} is not very helpful: it just specifies some compact subset K of the domain of analyticity without even saying what K is. The authors should provide a more informative and specific constraint on the numerical solution.
	\end{itquote}
	Rigorous arguments on the domain of validity of results such as Theorem 6 or \cite[Theorem IX.8.1]{HLW06} ought to be found, for example, in \cite{BeG94}. We added this reference, but we believe that entering discussions in this direction would be out of the scope of our work.
	\item \textbf{Answer to the following comments by Reviewer \#1}
	\begin{itquote}
		Second (90): for true, we need $t_n\geq 1$ \\ First (93): two terms inside parentheses been justified before their appearance here. are requested state justify bounds used. \\ Last help reader verify correct, write they use $t_n=nh$. an explicit bound $\sqrt{r}$ helps understand why $\mathcal O(e^{-\kappa (4mh)})$ \\ Why are the first two terms on the right-hand side of the first inequality of (94) bounded by $C_4 h^q$?
	\end{itquote}
	\textbf{and to the following comment by Reviewer \#2}
	\begin{itquote}
		I have not fully understood how this imposing of this terms should work in Eqs. (91) and (95).
	\end{itquote}
	We believe that the new version of the proof of Theorem 6, together with the proofs of Lemma 7 and Lemma 8, answer all the above questions.
	\item \textbf{Answer to the following comments by Reviewer \#1}
	\begin{itquote}
		Remark 9: -- From the point of view of probability theory, I do not think it is appropriate to refer to $p\to\infty$ as a 'deterministic limit'. It may be better to just write 'in the limit as $p\to\infty$'. -- Explain in more detail why the coefficient $M$ in Assumption 6 tends to 1 as $p\to\infty$.
	\end{itquote}
	We rephrased the Remark in light of this comment. In particular, the value $M$ does not \textit{tend} to 1, but it can be chosen arbitrarily close to 1 if $p \to \infty$.
	\item \textbf{Answer to the following comments by Reviewer \#1}
	\begin{itquote}
		Remark 10: To a reader unfamiliar with symplectic integrators, it is not immediately clear what is the significance of this remark with respect to the preceding results in this paper. If a connection exists, then the authors should state and explain it clearly; otherwise the remark does not serve any meaningful purpose and ought to be removed.
	\end{itquote}
	\textbf{and to the following comment by Reviewer \#2}
	\begin{itquote}
		I have not been able to build up an intuition about Remark 10 in light of Theorem 6. How do these two statements relate to each other? What exactly am I to make of this as an user of your method?
	\end{itquote}
	We believe that this issue is clarified with the addition to Remark 10 of the sentence 
	\begin{quote}
		Conversely, Theorem 6 proves that random step sizes do not spoil, under the assumptions specified above, the good long time properties of symplectic integrators with fixed step size.
	\end{quote}
	\item \textbf{Answer to the following comment by Reviewer \#1}
	\begin{itquote}
		Remark 11: 'We introduce ... the remainder $\widehat{S}_1$.' -- In the proof, the assumption is also used to simplify the terms in $\widehat{S}_2$.
	\end{itquote}
	For clarity, since $p \geq 3/2$ is now one assumption behind Lemma 8 and since we now avoided the splitting of $S$ into $\hat S_1$ and $\hat S_2$, we rephrased this sentence as
	\begin{quote}
		 As it can be noticed in the proof of Lemma 8, we introduce the assumption $p \geq 3/2$ in order to simplify the terms composing the remainder $S(\Delta, \eta)$.
	\end{quote}
\end{enumerate}

\section{Reviewer \#1} 
\begin{enumerate}
	\item 
	\begin{itquote} 
		``An additive random term could force the solution on the negative plane with a non-zero probability, which can become significantly big in case the magnitude of one component is small.'' -- This sentence is unclear, because it is not clear what can become significantly big, and it is not precisely clear what the component is of.
	\end{itquote}
	We modified the sentence above as 
	\begin{quote} In particular, an additive random term could force the solution on the negative plane with a non-zero probability, and this probability could become non-negligibly big in case the magnitude of one component of the solution is small \end{quote}
	\item 
	\begin{itquote} 
		Definition 1: ``... for any function $\Phi$ ... with all derivatives bounded uniformly on $\mathbb{R}^d$.'' -- From the point of view of probability theory, the class of ``test functions'' that one considers is the class of bounded, continuous functions. To avoid any confusion, the authors should state very clearly whether or not the test functions that they consider are bounded. I consider ``all derivatives'' to be imprecise, as certain readers may take this to mean that the test functions themselves are bounded, when in fact the authors consider unbounded test functions later, e.g. $\Phi(x):=x^\top x$. -- For brevity and simplicity, perhaps the authors could define the appropriate function class in an equation and use a symbol to refer to the function class afterwards, instead of repeatedly writing ``... with all derivatives bounded uniformly on $\mathbb{R}^d$''.
	\end{itquote}
	We introduced the symbol $\mathcal C^\infty_b(\R^d, \R)$ for the functions in $\mathcal C^\infty(\R^d, \R)$ with all derivatives bounded uniformly in $\R^d$. The function $\Phi$ that we consider in the numerical experiment is indeed unbounded on $\R^2$ ($d = 2$ being the dimension of the FitzHugh--Nagumo system). Nonetheless, the FitzHugh--Nagumo system is known to present periodic solutions lying in a bounded attractor $\mathcal A$, and if the numerical solver is stable the numerical solution will stay in a neighbourhood of this attractor, too. Therefore, the restriction of the function $\Phi\colon \mathcal A \to \R$, $x \mapsto x^\top x$ on the attractor is a valid test function.
	\item 
	\begin{itquote} 
		``and denote in the following ... the Markov generator on the step size $h$.'' I am aware that Conrad et al. use $\mathcal{L}^h$ for the infinitesimal generator of the Markov chain. However, I think this notation can be improved for the present article, for the following reasons: 1) $\mathcal{L}$ has already been used for the Lie derivative of the flow, and $\mathcal{L}$ and $\mathcal{L}^h$ are not related by taking ``powers''; 2) I think the infinitesimal generator should depend on the distribution $H_0$ from which the random time steps are drawn, and this dependence is just as important as the dependence on the deterministic step size $h$. If the authors wish to emphasise the dependence of the generator on $h$, then I think they should also emphasise its $H_0$-dependence as well, at least for the first instance of the infinitesimal generator. If the authors wish to do so, they can can omit the $H_0$ dependence in subsequent instances to simplify notation, but I think it is advantageous to the authors to remind the reader that the present setting is different from that of Conrad et al.
	\end{itquote}
	In order to answer to the first part of this comment, we remark that the semi-group notation for the infinitesimal generator $e^{h\mathcal L}$ involves the Lie derivative of the flow $\mathcal L$, which in fact resolves this notation clash. We added a reference to \cite[Section 4.3]{PaS08}, where this topic is treated extensively. For the problem of ``taking powers'', we agree that the notation $\mathcal L^h$ could be misleading, and we therefore changed it to $\mathcal L_h$, as for the infinitesimal generator of the Markov chain $\mathcal P_h$. Conversely to the operator $\diffL = f \cdot \nabla$, the expression of $\mathcal L_h$ cannot be written explicitly, and the exponential notation $\mathcal P_h = e^{h\mathcal L_h}$ is employed for analogy with the exact solution. \\
	We agree that the infinitesimal generator of the Markov chain depends on the distribution on the step sizes, as the infinitesimal generator of the probabilistic method defined in \cite{CGS17} depends on the distribution of the additive random variables $\xi_k$. Nonetheless, the index $h$ of $\mathcal P_h$ and $\mathcal L_h$ is chosen because these operators map an approximation of the solution at time $t$ to an approximation of the solution at time $t+h$. In fact, even though our method proceeds by random steps, the value $Y_k$ is still conceived as an approximation of $y(kh)$ (see in Section 2, just after (6), ``where $Y_k$ is still a random variable approximating $y(t_k)$ \ldots'' and/or Remark 5). Therefore we believe that writing explicitly the dependence on $H_0$ is not only unnecessary, but even not entirely correct.
	\item 
	\begin{itquote}	
		``hence given $h>0$ there exists an operator $\mathcal{P}_h$ such that '' -- As a service to the reader, provide a reference to a theorem or proposition that justifies the use of ``hence''. I do not expect all readers of this article to be familiar with homogeneous Markov chains.
	\end{itquote}
	and
	\begin{itquote}
		Also, as a service to the reader, provide a reference to a theorem or proposition that justifies (15). I do not expect all readers of this article to be familiar with homogeneous Markov chains.
	\end{itquote}
	We added a reference to \cite[Section 2.3]{Pav14}, where the theory of infinitesimal generator for homogeneous Markov chains is treated extensively.
	\item 
	\begin{itquote} 
		The authors should provide detailed, step-by-step, rigorously justified steps that proceed from (28) to the first inequality in (29). Do not use vague phrases such as 'Proceeding iteratively'. Note that 'proceeding iteratively' does not yield the first inequality in (29), even after using $w_0=W_0$. Instead, it yields $$\sup_{u\in\mathbb{R}^d}\vert W_k(u)-w_k(u)\vert \leq Ch^{min\{2p+1,q+1\}}\sum_{j=0}^{k-1}(1+Lh)^j.$$ In fact, using Gronwall's inequality for nonnegative sequences yields $$\sup_{u\in\mathbb{R}^d}\vert W_k(u)-w_k(u)\vert \leq Ch^{min\{2p+1,q+1\}}\exp\left(k(1+Lh)\right).$$ Since the upper bound of $k$ is $N=T/h$, the exponential will increase to infinity faster than any power of $h$.
	\end{itquote}
	We thank the referee for pointing this imprecision out. We modified the result, that now we believe being correct. Moreover, let us remark that since $1 + x \leq e^x$, the ``$1+$'' term disappears in the exponential and we have 
	\begin{equation*}
		\sum_{j=0}^{k-1}(1+Lh)^j \leq \sum_{j=0}^{k-1} e^{Lhj} \leq \sum_{j=0}^{k-1} e^{LT} \leq ke^{LT} \leq h^{-1} T e^{LT},
	\end{equation*}
	which yields
	\begin{equation*}
		\sup_{u\in\mathbb{R}^d}\vert W_k(u)-w_k(u)\vert \leq Ch^{\min\{2p, q\}} T e^{LT}.
	\end{equation*}
	\item 
	\begin{itquote} 
		In Assumption 4, if $\mathcal{L}^h$ depends on the distribution $H_0$ (which I think it does), then this assumption should also state something about the distribution $H_0$, not just the vector field $f$. At the very least, I would expect ``The function $f$ is such that ...'' to be changed to ``The function f and the distribution $H_0$ are such that ...''. Also, although it may be obvious to the authors, I think it should be stated explicitly as a service to the reader that the positive constant $L$ may depend on $f$ and $H_0$, but not on $\Phi$ or $h$.
	\end{itquote}
	We modified Assumption 4 as follows
	\begin{quote}
		The function $f$ and the distribution of the random time steps $H_k$, $k = 0, 1, \ldots$, are such that the operator $e^{h\diffL_h}$ satisfies for all functions $\Phi\in \mathcal C^\infty_b(\R^d, \R)$ and a positive constant $L$, 
		\begin{equation}
		\sup_{u\in\R^d} \abs{e^{h\diffL_h}\Phi(u)} \leq (1 + Lh)\sup_{u\in\R^d}\abs{\Phi(u)},
		\end{equation}
		where $L$ may depend on $f$ and on the distribution of the random time steps, but not on $\Phi$ or $h$.
	\end{quote}
	\item 
	\begin{itquote}
	``In the sub-optimal case ... are balanced.'' -- The authors could provide an explicit formula for $M$ in terms of $h$, $p$ and $q$ in the case that $p$ ``if for any''
	\end{itquote}
	A new formula has been added for treating this sub-optimal case.
	\item 
	\begin{itquote}
		The expression of the Hellinger distance is incorrect, because the integral on the right-hand side is not taken with respect to the prior. See Definition 6.35 in Stuart's Acta Numerica paper.
	\end{itquote}
	We adopted this expression for the Hellinger distance since we assumed that prior and posterior distributions admit a probability density function with respect to the Lebesgue measure. In this case, the Hellinger distance can be simplified and its expression is the one we provide. Since the section regarding Bayesian inverse problems delivers qualitative results, later confirmed by simple experiments, we decided to consider the case of finite-dimensional parameters. In this case, we feel that assuming that prior and posterior admit a probability density function is not limiting our analysis.
	\item 
	\begin{itquote}
		``the standard random walk Metropolis--Hastings is usually employed'' -- Provide evidence for this by citing some literature.
	\end{itquote}
	We corrected the sentence above with ``the standard random walk Metropolis--Hastings can be employed''. We believe that the standard implementation of Metropolis--Hastings is nowadays a common sampling tool, and that a list of references of papers employing this algorithm would add no value to our work.  
	\item 
	\begin{itquote}
		To make it explicitly clear how this section is connected to the preceding material (in particular, the introduction to Bayesian inverse problems), I recommend that the authors do the following: 1) Write '$Z=\varphi_h(y_0^\ast)+\epsilon$' instead of '$d= \varphi_h(y_0^\ast)+\epsilon$'. Upper case letters should be used for random variables and lower case letters should be used for deterministic values. 2) Specify the parameter space $\Theta$, observable, and linear forward operator. 3) As far as possible, use the same symbols as used in (99), (100), (101).
	\end{itquote}
	We modified the notation of this example by replacing $y_0 \leftarrow \theta$, $d \leftarrow Z$, $\bar y_0 \leftarrow \bar \theta$, $y_0^* \leftarrow \theta^*$ in order to get more uniformity with respect to the introduction to Bayesian inverse problems. Moreover, we added the sentence ``In this case, the parameter space is $\Theta = \R$ and the forward operator $\mathcal G$ is defined by $\mathcal G\colon \R \to \R$, $\mathcal G \colon \theta \mapsto \theta e^{-h}$''. 
	\item
	\begin{itquote}
		Section 8.1: The symbol '$\to$' and the phrase 'tends to' are used to suggest convergence. However, the authors do not specify the type of convergence. Thus, the statements should be considered only at an imprecise, heuristic level, and not at the level of rigorous mathematics. The authors should notify the reader of this.
	\end{itquote}
	We added the sentence ``In the following, we verify heuristically the convergence of the posterior distributions obtained with deterministic and probabilistic integrators with respect to a vanishing noise scale.''
	\item 
	\begin{itquote}
		It is difficult to distinguish the curves corresponding to different values of $\sigma$. I recommend that the authors reduce the range of values of $y_0$ in each subplot to make it easier for the reader to distinguish the curves for different values of $\sigma$
	\end{itquote}
	We increased the sizes of the plots and ``stretched'' the horizontal axis to make the lines more distinguishable. Nonetheless, we think that keeping the same horizontal range for the four figures renders the idea of how more concentrated deterministic posteriors are. Since the additive noise posterior densities have non-negligible values over the range $\theta \in [-1, 3]$, we believe that decreasing the range more would reduce the visual and conceptual impact of this figure.
	\item 
	\begin{itquote}
		Table 2: the sub-table for the explicit trapezoidal method should contain as many columns as the number of values of $h$ that were used.
	\end{itquote}
	Since for each one of the 5 values of $p$ we consider 5 different values of $h$, this would create a table with 20 columns (n. values of $p$ $\times$ $($n. values of $h$ - 1$)$). Therefore, we decided to write the average convergence slope over the set of step sizes for each value of $p$. We still believe that this choice renders our result more readable.
	\item 
	\begin{itquote}
		Section 9: The authors should specify all the parameters that they use in their experiments. For example, in some subsections below the value of the parameter $p$ is given, while in other subsections it is not. 
	\end{itquote}
	We reviewed the description of the numerical experiments and added the missing parameters.
	\item
	\begin{itquote}
		Some readers may assess that the variance of the Gaussian random variable is excessively small (on the order of $10^{-8}$) relative to the initial condition. The authors should explain why they chose such a small variance.
	\end{itquote}
	and
	\begin{itquote}
		``Hence, initial conditions with a different energy level with respect to the observation are endowed with a high value of likelihood'' -- The authors should explicitly state the likelihood that they use and clearly explain how the energy level and the likelihood are connected.
	\end{itquote}
	We modified the introduction of the numerical experiment in order to clarify our choice of likelihood and the small noise as
	\begin{quote}
		Noise is then set to be a Gaussian random variable $\epl \sim \mathcal{N}(0, \sigma_\epl^2 I)$, where $\sigma_\epl = 5 \cdot 10^{-4}$, and we fix a standard Gaussian prior on the initial condition, i.e., $\pi_0 = \mathcal N(0, I)$, so that the likelihood is given by (101). We choose the observational noise to have a small variance (i.e., of order $\mathcal O(10^{-8})$) as in this case classical solvers present the misleading overconfident behaviour explained in Section 8.
	\end{quote}
	The observation about energy levels and likelihood is modified as
	\begin{quote}
		Hence, initial conditions with a different energy level with respect to the observation are mapped by the approximate forward model to points which are close to the observations, and as a result the posterior distribution is concentrated far from the true value.
	\end{quote} 
	The meaning of the above sentence is that if the approximate forward model is not conserving the Hamiltonian, the energy state of the approximate solution at time $t$ will be different than the one of the initial condition. Let us assume without loss of generality that the numerical integrator causes a positive drift in energy. In this case, an initial condition with a lower energy than the observations will be ``seen'' under the posterior as the most likely. Conversely, if the forward map conserves (i.e., approximately conserves) the Hamiltonian, \textit{at least} the correctness on the energy for the solution of the inverse problem with respect to the observations can be trusted.
	\item 
	\begin{itquote}
		{\normalfont Regarding the proof of Lemma 6.} The authors need to bound the $Mh$ term by a constant that does not depend on $h$.
	\end{itquote}
	We added to the statement of the Theorem ``and if $h \leq \bar h < \infty$'' and bounded $Mh \leq M\bar h$. In the following results, we most often assume $\bar h = 1$.
	\item 
	\begin{itquote}
		 Proof of Lemma 6: The authors only consider the case where $H_j\geq h$. They should discuss the case where $H_j$ ``in the mean-square sense''
	\end{itquote}
	The proof is actually valid for $H_j < h$ as well. We nonetheless modified it for clarity by introducing the notation
	\begin{quote}
		In the following, we denote by $\llbracket a, b \rrbracket$ the interval $\llbracket a, b \rrbracket = [a, b]$ if $a < b$ and $\llbracket a, b \rrbracket = [b, a]$ if $a \geq b$.
	\end{quote}
	The rest of the proof is unchanged, and we believe correct, by modifying the intervals $[h, H_j]$ to $\llbracket h, H_j \rrbracket$.
\end{enumerate}

\section{Reviewer \#2} 
\begin{enumerate}
	\item 
	\begin{itquote}
		Where did $M^{-1}$ go from (54) to (55)? Cf. (51)?
	\end{itquote}
	The Monte Carlo estimator is unbiased, therefore $\E(\hat Z_{N,M} - Z) = \E(Z_N - Z)$ and then Theorem 1 can be applied consequently. We nonetheless explicitly highlighted this fact this in the revised version.
	\item 
	\begin{itquote}
		System (122) might be easier to parse written as a second-order system.
	\end{itquote}
	We agree with the reviewer on the fact that the Kepler system is oftentimes found in literature as a second-order system. Nonetheless, since our work treats first-order equations, we believe that if we first presented the Kepler system as a second-order system, we would have to write its first-order transformation too, which would make the numerical experiment heavier to digest for the reader.  
\end{enumerate}

\bibliographystyle{siam}
\bibliography{anmc}

\end{document}
